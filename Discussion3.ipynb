{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what ways do you think Recommender Systems reinforce human bias?\n",
    "Reflecting on the techniques we have covered, do you think recommender\n",
    "systems reinforce or help to prevent unethical targeting or customer\n",
    "segmentation?  Please provide one or more examples to support your arguments.\n",
    "\n",
    "\n",
    "The technology of recommending products and services to users illustrates\n",
    "the increasing influence of machine learning over important decisions in our lives.\n",
    "Since automated recommendation is based on input data, it carries inherent risk\n",
    "of using data in unacceptable or unfair ways.\n",
    "\n",
    "If a recommendation uses criteria that are unfair or discriminatory to some users,\n",
    "that can adversely affect a business's public image, in addition to the ethical and\n",
    "legal issues raised.\n",
    "\n",
    "Recommender systems can reinforce bias in several ways. First, there may be bias in\n",
    "selection of criteria for making recommendations. Use of certain kinds of data is\n",
    "justifiably deemed unfair or discriminatory, such as those related to racial or\n",
    "gender attributes.\n",
    "\n",
    "Secondly, a recommender system can learn to predict outcomes based on a combination\n",
    "of attributes that was not intended by the designer, but learned (or extracted) from the data\n",
    "used for training the system. It may learn to segment users according to attributes\n",
    "that are unfair or unintended.\n",
    "\n",
    "It can be argued that recommender systems by themselves neither reinforce nor mitigate bias,\n",
    "and that humans are responsible for how the technology is used. In any case, the\n",
    "business or entity developing the system and profiting from its use is legally responsible\n",
    "for any bias in its results, so this is largely a fruitless debate.\n",
    "\n",
    "An example of bias in recommendation systems is a bias in favor of male authors as\n",
    "describe in the study https://md.ekstrandom.net/blog/2018/07/recsys-author-gender.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
